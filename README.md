# MLOps: Wine Quality Prediction with Deployment

Endâ€‘toâ€‘end **MLOps** project that predicts wine quality from physicochemical features. Productionâ€‘minded structure with modular code, tracked experiments, and CI/CD.

**Live app (Azure):** *coming soon â†’* **\[ADD YOUR LINK HERE]**

---

## Why this project

* ğŸ§± **Modular pipeline** with clear stages (ingest â†’ validate â†’ transform â†’ train â†’ evaluate â†’ serve).
* ğŸ§ª **Experiment tracking** with MLflow (compatible with DagsHub remote).
* ğŸ³ **Dockerized** for reproducibility and cloud deploys.
* âš™ï¸ **Configâ€‘driven** (YAML) so runs are parameterized and repeatable.

> Repo highlights include `config/`, `datasets/`, `src/MLOPS/`, `app.py`, `main.py`, `params.yaml`, `schema.yaml`, `Dockerfile`, and `requirements.txt`. See the repo for the full layout.

---

## Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                       CI/CD                        â”‚
                â”‚  (GitHub Actions â†’ build, test, image, deploy)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
Raw data  â”€â”€â–º  Ingestion  â”€â”€â–º  Validation  â”€â”€â–º  Transformation  â”€â”€â–º  Training  â”€â”€â–º  Evaluation
 (CSV)         (load)           (schema)         (FE, scaling)        (model)         (MLflow)
                                                                                 â”‚
                                                                                 â–¼
                                                                             Registry
                                                                                 â”‚
                                                                                 â–¼
                                                                           Inference API
                                                                              (`app.py`)
```

---

## Project structure

```
.
â”œâ”€â”€ config/                # config.yaml, stage configs
â”œâ”€â”€ datasets/              # raw/processed data
â”œâ”€â”€ logs/                  # pipeline & app logs
â”œâ”€â”€ research/              # notebooks / scratch
â”œâ”€â”€ src/MLOPS/             # package with components & pipelines
â”œâ”€â”€ templates/             # index.html
â”œâ”€â”€ app.py                 # inference service (FastAPI/Streamlit/Flask)
â”œâ”€â”€ main.py                # pipeline runner / orchestrator
â”œâ”€â”€ params.yaml            # hyperparams & run settings
â”œâ”€â”€ schema.yaml            # data schema for validation
â”œâ”€â”€ Dockerfile             # container image
â”œâ”€â”€ requirements.txt       # Python deps
â””â”€â”€ README.md
```

---

## Datasets

* **Source**: UCI Wine Quality (red/white) physicochemical dataset.
* **Target**: `quality` (regression or ordinal classification depending on params).

Place raw CSVs under `datasets/` or update the path in `config.yaml` and `params.yaml`.

---

## Moduleâ€‘byâ€‘module

**1) Data Ingestion**

* Reads raw CSVs, handles train/test split, writes to `datasets/processed/`.

**2) Data Validation**

* Enforces `schema.yaml` (dtypes, ranges, required cols). Fails fast on drift/missing columns.

**3) Data Transformation**

* Feature engineering, imputation, scaling; persists transformers for inference parity.

**4) Model Trainer**

* Trains baseline + tuned model (e.g., ElasticNet/RandomForest/XGBoost as configured). Saves model artifacts.

**5) Model Evaluation**

* Computes metrics (RMSE/MAE/RÂ²), logs params/metrics/artifacts to **MLflow**; supports DagsHub tracking URI.

**6) Inference Service (`app.py`)**

* Loads the latest model + transformer bundle; exposes `predict` endpoint or Streamlit UI.

**7) Orchestration (`main.py`)**

* Runs stages sequentially/individually; controlled by `params.yaml` and `config.yaml`.

---

## Getting started

### 1) Setup

```bash
# clone & create env
git clone https://github.com/Vatsal-Founder/MLOPS_project.git
cd MLOPS_project
python -m venv .venv && source .venv/bin/activate    # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Configure

Edit **`config/config.yaml`**, **`params.yaml`**, and **`schema.yaml`** for paths, splits, hyperparams, and schema rules. For MLflow remote (e.g., DagsHub):

```bash
export MLFLOW_TRACKING_URI=https://dagshub.com/<user>/<repo>.mlflow
export MLFLOW_TRACKING_USERNAME=<user>
export MLFLOW_TRACKING_PASSWORD=<token>
```

### 3) Run the pipeline

```bash
# endâ€‘toâ€‘end
python main.py

# OR run stageâ€‘wise (examples)
python main.py --stage ingest
python main.py --stage validate
python main.py --stage transform
python main.py --stage train
python main.py --stage evaluate
```

Artifacts (models/transformers) are saved to the configured `artifacts/` path; runs and metrics appear in MLflow.

### 4) Serve predictions

```bash
# option A: FastAPI/Flask style
python app.py
# option B: Streamlit UI (if implemented)
streamlit run app.py
```

Visit `http://localhost:8000` or `http://localhost:8501` depending on your entrypoint.

---

## Docker

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
# pipeline
# CMD ["python", "main.py"]
# inference (FastAPI)
# CMD ["python", "app.py"]
```

Build & run:

```bash
docker build -t wine-mlops .
# run pipeline
# docker run --rm wine-mlops python main.py
# run API (map a port)
docker run -p 8000:8000 wine-mlops python app.py
```

---

## CI/CD (GitHub Actions)

Typical workflow:

1. Lint & unit checks
2. Build Docker image
3. Run pipeline on push to `main` (optional)
4. Push image to registry
5. Deploy to Azure (see below)

> This repo includes a workflows folder. Adapt it with your Azure credentials and environment secrets.

---

## Azure deployment (placeholder)

* **Option A â€” Azure App Service (inference):**

  * Build image â†’ push to **Azure Container Registry (ACR)**.
  * Create Web App for Containers â†’ set env vars (MLflow URI, data paths, keys).
  * Configure startup command: `python app.py` (or `gunicorn` if applicable).
  * Public URL: **\[ADD YOUR AZURE APP LINK HERE]**

* **Option B â€” Azure ML (batch/online endpoints):**

  * Register model artifact; create env from `requirements.txt`.
  * Define inference entry (`app.py` or `score.py`), deploy endpoint.

*(Keep this section updated with your exact steps & URLs.)*

---

## Configuration files

* **`config/config.yaml`** â€“ paths and stage toggles
* **`params.yaml`** â€“ hyperparameters (splits, model params)
* **`schema.yaml`** â€“ column names, dtypes, ranges

---

## License

GPLâ€‘3.0 Â© Vatsal Founder
